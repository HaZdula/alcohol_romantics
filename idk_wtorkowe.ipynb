{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, recall_score, precision_score, plot_precision_recall_curve, mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "#import xgboost\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "np.random.seed(123)\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "pd.options.display.max_columns = None\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"students-all.csv\")\n",
    "# remove rownames\n",
    "df = df.iloc[:,1:]\n",
    "df['romantic'] = np.where(df['romantic']=='yes', 1, 0)\n",
    "df_dummies = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmodyfikowana fun encodująca dane. Beware: target musi być wynikiem encodingu, jeśli romantic znajduje się jako kolumna do zenkodowania -> \"romantic_yes\"/\"romantic_1\" itp, dlatego lepiej zamienić \"romanitc\" ifelsem ręcznie na 0 i 1 dać jako target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fast(df, max_depth, target, encoder = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    From Standard cross validation differs in data partitnion. Due to optimizing model on validation set,\n",
    "    we get final AUC score from equally big test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # shuffling index\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    n = len(df)\n",
    "    \n",
    "    # 5 fold cross validation\n",
    "    kf = KFold(n_splits=5)\n",
    "        \n",
    "    \n",
    "    ret = []\n",
    "    tpr_arr = []\n",
    "    fpr_arr = []\n",
    "    \n",
    "    # we will make test 10% and validation 10%\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        \n",
    "        train = df.iloc[train_index,:]\n",
    "        if encoder:\n",
    "            encoder.fit(train, train[target])\n",
    "            train = encoder.transform(train)\n",
    "        \n",
    "        v_ind = test_index[0:(len(test_index)//2)] \n",
    "        t_ind = test_index[(len(test_index)//2):len(test_index)]\n",
    "        \n",
    "        validation = df.iloc[v_ind,:]\n",
    "        if encoder: validation = encoder.transform(validation)\n",
    "        \n",
    "        test = df.iloc[t_ind,:]\n",
    "        if encoder: test = encoder.transform(test)\n",
    "        \n",
    "        label_train = train[target]\n",
    "        label_val = validation[target]\n",
    "        label_test = test[target]\n",
    "\n",
    "        df_train = train.drop([target], axis = 1)\n",
    "        df_test  = test.drop([target], axis = 1)\n",
    "        df_val  = validation.drop([target], axis = 1)\n",
    "        \n",
    "        dtrain = xgb.DMatrix(data = df_train, label=label_train)\n",
    "        dval = xgb.DMatrix(data = df_val, label=label_val)\n",
    "        dtest = xgb.DMatrix(data = df_test, label=label_val)\n",
    "        \n",
    "        param = {'max_depth': max_depth, 'objective': 'binary:logistic', 'eval_metric':'auc'}\n",
    "        \n",
    "        evallist = [(dval, 'eval'), (dtrain, 'train')]\n",
    "        \n",
    "        num_round = 100\n",
    "        \n",
    "        bst = xgb.train(param, dtrain, num_round, evallist, verbose_eval=0)\n",
    "        y_pred = bst.predict(dtest, ntree_limit=bst.best_ntree_limit)\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(label_test.to_numpy(), y_pred)\n",
    "\n",
    "        \n",
    "        ret.append(metrics.auc(fpr, tpr))\n",
    "        \n",
    "        fpr_arr.append(fpr)\n",
    "        tpr_arr.append(tpr)\n",
    "        \n",
    "    # fpr and tpr arrays are problematic, we will get them from median AUC score\n",
    "    # note that we are returning mean auc score, so it is not ideal \n",
    "    index = np.where(np.mean(np.array(ret))== np.mean(np.array(ret)))[0][0]\n",
    "    \n",
    "    \n",
    "    return np.array(ret).mean(), bst, fpr_arr[index],tpr_arr[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc, m, _,_ = train_fast(df_dummies, 19, \"romantic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummies.drop(['romantic'], axis = 1)\n",
    "X = xgb.DMatrix(X)\n",
    "y = df_dummies['romantic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = m.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939723569486109"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_encoder(encoder, model):\n",
    "    \"\"\"\n",
    "    Funkcja działająca jako pipeline w następujących krokach:\n",
    "    * kodowanie\n",
    "    * dopasowanie\n",
    "    * liczenie rmse i r2\n",
    "    \"\"\"\n",
    "    #logreg = LogisticRegression(*args)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop(['romantic'], axis = 1),y, test_size = 0.3, random_state = 66)\n",
    "    \n",
    "    encoder.fit(X_train, y_train)\n",
    "    \n",
    "    X_train = encoder.transform(X_train)\n",
    "    X_test = encoder.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    #mse = mean_squared_error(y_test, y_pred)\n",
    "    #rmse = np.sqrt(mse)\n",
    "    #r2 = r2_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns= ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
    "       'higher', 'internet', 'famrel', 'freetime', 'goout', 'Dalc',\n",
    "       'Walc', 'health', 'major']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = [ce.BackwardDifferenceEncoder(cols=columns),\n",
    "ce.BaseNEncoder(cols=columns),\n",
    "ce.BinaryEncoder(cols=columns),\n",
    "ce.CatBoostEncoder(cols=columns),\n",
    "ce.HashingEncoder(cols=columns),\n",
    "ce.HelmertEncoder(cols=columns),\n",
    "ce.JamesSteinEncoder(cols=columns),\n",
    "ce.LeaveOneOutEncoder(cols=columns),\n",
    "ce.MEstimateEncoder(cols=columns),\n",
    "ce.OneHotEncoder(cols=columns),\n",
    "ce.OrdinalEncoder(cols=columns),\n",
    "ce.SumEncoder(cols=columns),\n",
    "ce.PolynomialEncoder(cols=columns),\n",
    "ce.TargetEncoder(cols=columns),\n",
    "ce.WOEEncoder(cols=columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def measure_encodesrs(model):\n",
    "    res = pd.DataFrame()\n",
    "    names = ['BackwardDifferenceEncoder',\n",
    "            'BaseNEncoder',\n",
    "            'BinaryEncoder',\n",
    "            'CatBoostEncoder',\n",
    "             'HashingEncoder',\n",
    "             'HelmertEncoder',\n",
    "             'JamesSteinEncoder',\n",
    "             'LeaveOneOutEncoder',\n",
    "             'MEstimateEncoder',\n",
    "             'OneHotEncoder',\n",
    "             'OrdinalEncoder',\n",
    "             'SumEncoder',\n",
    "             'PolynomialEncoder',\n",
    "             'TargetEncoder',\n",
    "             'WOEEncoder'\n",
    "            ]\n",
    "    for i in range(len(enc)):\n",
    "        auc = measure_encoder(enc[i], model)\n",
    "        res = res.append({\"Name\": names[i], \"auc\": auc}, ignore_index = True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "models = [#AdaBoostClassifier(), \n",
    "          BaggingClassifier(), \n",
    "          ExtraTreesClassifier(),\n",
    "          RandomForestClassifier(), \n",
    "          GradientBoostingClassifier(),\n",
    "         XGBClassifier(),\n",
    "    XGBRFClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Name       auc\n",
      "0   BackwardDifferenceEncoder  0.618635\n",
      "1                BaseNEncoder  0.648426\n",
      "2               BinaryEncoder  0.655366\n",
      "3             CatBoostEncoder  0.641973\n",
      "4              HashingEncoder  0.554234\n",
      "5              HelmertEncoder  0.644935\n",
      "6           JamesSteinEncoder  0.639984\n",
      "7          LeaveOneOutEncoder  0.659300\n",
      "8            MEstimateEncoder  0.614215\n",
      "9               OneHotEncoder  0.627564\n",
      "10             OrdinalEncoder  0.651874\n",
      "11                 SumEncoder  0.652847\n",
      "12          PolynomialEncoder  0.663764\n",
      "13              TargetEncoder  0.628580\n",
      "14                 WOEEncoder  0.619165\n",
      "                         Name       auc\n",
      "0   BackwardDifferenceEncoder  0.700451\n",
      "1                BaseNEncoder  0.717822\n",
      "2               BinaryEncoder  0.695014\n",
      "3             CatBoostEncoder  0.717822\n",
      "4              HashingEncoder  0.573064\n",
      "5              HelmertEncoder  0.736165\n",
      "6           JamesSteinEncoder  0.724275\n",
      "7          LeaveOneOutEncoder  0.738154\n",
      "8            MEstimateEncoder  0.731215\n",
      "9               OneHotEncoder  0.707435\n",
      "10             OrdinalEncoder  0.733690\n",
      "11                 SumEncoder  0.736165\n",
      "12          PolynomialEncoder  0.730198\n",
      "13              TargetEncoder  0.740629\n",
      "14                 WOEEncoder  0.749072\n",
      "                         Name       auc\n",
      "0   BackwardDifferenceEncoder  0.672162\n",
      "1                BaseNEncoder  0.646879\n",
      "2               BinaryEncoder  0.658283\n",
      "3             CatBoostEncoder  0.665223\n",
      "4              HashingEncoder  0.577970\n",
      "5              HelmertEncoder  0.654305\n",
      "6           JamesSteinEncoder  0.646879\n",
      "7          LeaveOneOutEncoder  0.680118\n",
      "8            MEstimateEncoder  0.672162\n",
      "9               OneHotEncoder  0.672649\n",
      "10             OrdinalEncoder  0.653819\n",
      "11                 SumEncoder  0.700937\n",
      "12          PolynomialEncoder  0.721269\n",
      "13              TargetEncoder  0.688030\n",
      "14                 WOEEncoder  0.654305\n",
      "                         Name       auc\n",
      "0   BackwardDifferenceEncoder  0.589418\n",
      "1                BaseNEncoder  0.579517\n",
      "2               BinaryEncoder  0.583982\n",
      "3             CatBoostEncoder  0.658327\n",
      "4              HashingEncoder  0.542786\n",
      "5              HelmertEncoder  0.620182\n",
      "6           JamesSteinEncoder  0.658327\n",
      "7          LeaveOneOutEncoder  0.658327\n",
      "8            MEstimateEncoder  0.658327\n",
      "9               OneHotEncoder  0.613729\n",
      "10             OrdinalEncoder  0.586457\n",
      "11                 SumEncoder  0.613729\n",
      "12          PolynomialEncoder  0.626105\n",
      "13              TargetEncoder  0.658327\n",
      "14                 WOEEncoder  0.662792\n",
      "                         Name       auc\n",
      "0   BackwardDifferenceEncoder  0.665797\n",
      "1                BaseNEncoder  0.708451\n",
      "2               BinaryEncoder  0.708451\n",
      "3             CatBoostEncoder  0.681665\n",
      "4              HashingEncoder  0.600866\n",
      "5              HelmertEncoder  0.720341\n",
      "6           JamesSteinEncoder  0.681665\n",
      "7          LeaveOneOutEncoder  0.681665\n",
      "8            MEstimateEncoder  0.681665\n",
      "9               OneHotEncoder  0.725778\n",
      "10             OrdinalEncoder  0.671764\n",
      "11                 SumEncoder  0.725778\n",
      "12          PolynomialEncoder  0.707921\n",
      "13              TargetEncoder  0.681665\n",
      "14                 WOEEncoder  0.681665\n",
      "                         Name       auc\n",
      "0   BackwardDifferenceEncoder  0.545704\n",
      "1                BaseNEncoder  0.552687\n",
      "2               BinaryEncoder  0.552687\n",
      "3             CatBoostEncoder  0.559097\n",
      "4              HashingEncoder  0.533327\n",
      "5              HelmertEncoder  0.566036\n",
      "6           JamesSteinEncoder  0.559097\n",
      "7          LeaveOneOutEncoder  0.559097\n",
      "8            MEstimateEncoder  0.559097\n",
      "9               OneHotEncoder  0.557594\n",
      "10             OrdinalEncoder  0.552643\n",
      "11                 SumEncoder  0.553129\n",
      "12          PolynomialEncoder  0.555118\n",
      "13              TargetEncoder  0.559097\n",
      "14                 WOEEncoder  0.559097\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "for m in models:\n",
    "    print(measure_encodesrs(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_res = []\n",
    "for e in enc:\n",
    "    auc,_, _,_ = train_fast(df, 19, 'romantic', e)\n",
    "    auc_res.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BackwardDifferenceEncoder</td>\n",
       "      <td>0.827959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaseNEncoder</td>\n",
       "      <td>0.825840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BinaryEncoder</td>\n",
       "      <td>0.876437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostEncoder</td>\n",
       "      <td>0.799720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HashingEncoder</td>\n",
       "      <td>0.648465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HelmertEncoder</td>\n",
       "      <td>0.809558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JamesSteinEncoder</td>\n",
       "      <td>0.836771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LeaveOneOutEncoder</td>\n",
       "      <td>0.811583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MEstimateEncoder</td>\n",
       "      <td>0.804641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OneHotEncoder</td>\n",
       "      <td>0.837627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OrdinalEncoder</td>\n",
       "      <td>0.847049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SumEncoder</td>\n",
       "      <td>0.816347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PolynomialEncoder</td>\n",
       "      <td>0.854093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TargetEncoder</td>\n",
       "      <td>0.838998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WOEEncoder</td>\n",
       "      <td>0.811759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      encoder       auc\n",
       "0   BackwardDifferenceEncoder  0.827959\n",
       "1                BaseNEncoder  0.825840\n",
       "2               BinaryEncoder  0.876437\n",
       "3             CatBoostEncoder  0.799720\n",
       "4              HashingEncoder  0.648465\n",
       "5              HelmertEncoder  0.809558\n",
       "6           JamesSteinEncoder  0.836771\n",
       "7          LeaveOneOutEncoder  0.811583\n",
       "8            MEstimateEncoder  0.804641\n",
       "9               OneHotEncoder  0.837627\n",
       "10             OrdinalEncoder  0.847049\n",
       "11                 SumEncoder  0.816347\n",
       "12          PolynomialEncoder  0.854093\n",
       "13              TargetEncoder  0.838998\n",
       "14                 WOEEncoder  0.811759"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"encoder\": ['BackwardDifferenceEncoder',\n",
    "            'BaseNEncoder',\n",
    "            'BinaryEncoder',\n",
    "            'CatBoostEncoder',\n",
    "             'HashingEncoder',\n",
    "             'HelmertEncoder',\n",
    "             'JamesSteinEncoder',\n",
    "             'LeaveOneOutEncoder',\n",
    "             'MEstimateEncoder',\n",
    "             'OneHotEncoder',\n",
    "             'OrdinalEncoder',\n",
    "             'SumEncoder',\n",
    "             'PolynomialEncoder',\n",
    "             'TargetEncoder',\n",
    "             'WOEEncoder'], \n",
    "             \"auc\": auc_res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_res = []\n",
    "for e in enc:\n",
    "    auc,_, _,_ = train_fast(df, 19, 'romantic', e)\n",
    "    auc_res.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BackwardDifferenceEncoder</td>\n",
       "      <td>0.831567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaseNEncoder</td>\n",
       "      <td>0.858728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BinaryEncoder</td>\n",
       "      <td>0.829732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostEncoder</td>\n",
       "      <td>0.824604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HashingEncoder</td>\n",
       "      <td>0.627361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HelmertEncoder</td>\n",
       "      <td>0.853010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JamesSteinEncoder</td>\n",
       "      <td>0.817299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LeaveOneOutEncoder</td>\n",
       "      <td>0.848909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MEstimateEncoder</td>\n",
       "      <td>0.837989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OneHotEncoder</td>\n",
       "      <td>0.846375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OrdinalEncoder</td>\n",
       "      <td>0.838387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SumEncoder</td>\n",
       "      <td>0.844110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PolynomialEncoder</td>\n",
       "      <td>0.848390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TargetEncoder</td>\n",
       "      <td>0.810888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WOEEncoder</td>\n",
       "      <td>0.835331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      encoder       auc\n",
       "0   BackwardDifferenceEncoder  0.831567\n",
       "1                BaseNEncoder  0.858728\n",
       "2               BinaryEncoder  0.829732\n",
       "3             CatBoostEncoder  0.824604\n",
       "4              HashingEncoder  0.627361\n",
       "5              HelmertEncoder  0.853010\n",
       "6           JamesSteinEncoder  0.817299\n",
       "7          LeaveOneOutEncoder  0.848909\n",
       "8            MEstimateEncoder  0.837989\n",
       "9               OneHotEncoder  0.846375\n",
       "10             OrdinalEncoder  0.838387\n",
       "11                 SumEncoder  0.844110\n",
       "12          PolynomialEncoder  0.848390\n",
       "13              TargetEncoder  0.810888\n",
       "14                 WOEEncoder  0.835331"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"encoder\": ['BackwardDifferenceEncoder',\n",
    "            'BaseNEncoder',\n",
    "            'BinaryEncoder',\n",
    "            'CatBoostEncoder',\n",
    "             'HashingEncoder',\n",
    "             'HelmertEncoder',\n",
    "             'JamesSteinEncoder',\n",
    "             'LeaveOneOutEncoder',\n",
    "             'MEstimateEncoder',\n",
    "             'OneHotEncoder',\n",
    "             'OrdinalEncoder',\n",
    "             'SumEncoder',\n",
    "             'PolynomialEncoder',\n",
    "             'TargetEncoder',\n",
    "             'WOEEncoder'], \n",
    "             \"auc\": auc_res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OneHotEncoder(cols=columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['romantic'], axis=1),df['romantic'], test_size = 0.2, random_state = 666)\n",
    "X_y_train = X_train.copy()\n",
    "X_y_train['romantic'] = y_train\n",
    "X_test_trans = encoder.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc,model, _,_ = train_fast(X_y_train, 19, 'romantic', ce.OneHotEncoder(cols=columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_trans_xgb = xgb.DMatrix(X_test_trans)\n",
    "y_pred = model.predict(X_test_trans_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5726495726495726"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_dummies.drop(['romantic'], axis=1),\n",
    "                                                    df['romantic'], test_size = 0.2, random_state = 666)\n",
    "X_y_train = X_train.copy()\n",
    "X_y_train['romantic'] = y_train\n",
    "#X_test_trans = encoder.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc,model, _,_ = train_fast(X_y_train, 19, 'romantic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_xgb = xgb.DMatrix(X_test)\n",
    "y_pred = model.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.756184103811841"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
