{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(cols=['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob',\n",
       "                    'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid',\n",
       "                    'activities', 'nursery', 'higher', 'internet', 'major'],\n",
       "              drop_invariant=False, handle_missing='value',\n",
       "              handle_unknown='value', return_df=True, use_cat_names=False,\n",
       "              verbose=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = ce.OneHotEncoder()\n",
    "\n",
    "df = pd.read_csv(\"students-all.csv\").iloc[:,1:]\n",
    "y = df.romantic\n",
    "df = df.drop(\"romantic\", axis =1)\n",
    "\n",
    "encoder.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_hot = encoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school_1', 'school_2', 'sex_1', 'sex_2', 'age', 'address_1',\n",
       "       'address_2', 'famsize_1', 'famsize_2', 'Pstatus_1', 'Pstatus_2', 'Medu',\n",
       "       'Fedu', 'Mjob_1', 'Mjob_2', 'Mjob_3', 'Mjob_4', 'Mjob_5', 'Fjob_1',\n",
       "       'Fjob_2', 'Fjob_3', 'Fjob_4', 'Fjob_5', 'reason_1', 'reason_2',\n",
       "       'reason_3', 'reason_4', 'guardian_1', 'guardian_2', 'guardian_3',\n",
       "       'traveltime', 'studytime', 'failures', 'schoolsup_1', 'schoolsup_2',\n",
       "       'famsup_1', 'famsup_2', 'paid_1', 'paid_2', 'activities_1',\n",
       "       'activities_2', 'nursery_1', 'nursery_2', 'higher_1', 'higher_2',\n",
       "       'internet_1', 'internet_2', 'famrel', 'freetime', 'goout', 'Dalc',\n",
       "       'Walc', 'health', 'absences', 'G1', 'G2', 'G3', 'major_1', 'major_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one_hot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(data, encoder):\n",
    "    \"\"\"\n",
    "    Parsing data to the same format as in \"students-all.csv\"\n",
    "    \n",
    "    returns: nicks array and dataframe\n",
    "    \"\"\"\n",
    "    nicks = np.array(data['Nick'])\n",
    "    mails = np.array(data['Feedback mail'])\n",
    "    data = data.iloc[:, 2:-1]\n",
    "\n",
    "    column_names = [\n",
    "        'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob',\n",
    "        'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures',\n",
    "        'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'internet',\n",
    "        'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences',\n",
    "        'G1', 'G2', 'G3'\n",
    "    ]\n",
    "\n",
    "    data.columns = column_names\n",
    "\n",
    "    # deafults\n",
    "    data['school'] = np.repeat(\"GP\", data.shape[0])\n",
    "    data['major'] = np.repeat(\"mat\", data.shape[0])\n",
    "    data['higher'] = np.repeat(\"yes\", data.shape[0])\n",
    "\n",
    "    # corect order\n",
    "    data = data[[\n",
    "        'school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu',\n",
    "        'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime',\n",
    "        'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities',\n",
    "        'nursery', 'higher', 'internet', 'famrel', 'freetime', 'goout', 'Dalc',\n",
    "        'Walc', 'health', 'absences', 'G1', 'G2', 'G3', 'major'\n",
    "    ]]\n",
    "    \n",
    "    data['age'] = pd.to_numeric(data['age'])\n",
    "    data['sex'] = np.where(data.sex == 'Male', 'M', 'F')\n",
    "    data['address'] = np.where(data.address == 'Rural', 'R', 'U')\n",
    "    data['famsize'] = np.where(data.famsize == 'more than 3', 'GT3', 'LE3')\n",
    "    data['Pstatus'] = np.where(data.Pstatus == 'living apart', 'A', 'T')\n",
    "\n",
    "    d1 = {\n",
    "        'none': 0,\n",
    "        'primary education': 1,\n",
    "        'middle school': 2,\n",
    "        'high school': 3,\n",
    "        'higher education': 4\n",
    "    }\n",
    "\n",
    "    data['Medu'] = [d1[item] for item in list(data.Medu)]\n",
    "    data['Fedu'] = [d1[item] for item in list(data.Fedu)]\n",
    "\n",
    "    d2 = {\n",
    "        'teacher': 'teacher',\n",
    "        'healthcare': 'health',\n",
    "        'civil services': 'civil',\n",
    "        'home': 'at_home',\n",
    "        'other': 'other'\n",
    "    }\n",
    "\n",
    "    data['Mjob'] = [d2[item] for item in list(data.Mjob)]\n",
    "    data['Fjob'] = [d2[item] for item in list(data.Fjob)]\n",
    "\n",
    "    d3 = {\n",
    "        'close to home': 'home',\n",
    "        'school reputation': 'reputation',\n",
    "        'course preference': 'course',\n",
    "        'other': 'other'\n",
    "    }\n",
    "\n",
    "    data['reason'] = [d3[item] for item in list(data.reason)]\n",
    "    \n",
    "    d4 = {'Mother':'mother', 'Father':'father', 'other':'other'}\n",
    "    \n",
    "    data['guardian'] = [d4[item] for item in list(data.guardian)]\n",
    "\n",
    "    d5 = {'< 15':1, '15-30':2, '30-60':3,'60 >':4}\n",
    "    \n",
    "    data['traveltime'] = [d5[item] for item in list(data.traveltime)]\n",
    "    \n",
    "    d6 = {'< 2':1, '2-5':2, '5-10':3,'10 >':4}\n",
    "    \n",
    "    data['studytime'] = [d6[item] for item in list(data.studytime)]\n",
    "    \n",
    "    data['G1'] = np.array((pd.to_numeric(data.G1)/5)*20 , dtype = 'int64')\n",
    "    data['G2'] = np.array((pd.to_numeric(data.G2)/5)*20 , dtype = 'int64') \n",
    "    data['G3'] = np.array((pd.to_numeric(data.G3)/5)*20 , dtype = 'int64')\n",
    "    \n",
    "    data['absences'] = np.array(pd.to_numeric(data.absences) , dtype = 'int64')\n",
    "    data['failures'] = np.array(data.failures, dtype = 'int64')\n",
    "    data['famrel']   = np.array(data.famrel, dtype = 'int64')\n",
    "    data['freetime'] = np.array(data.freetime, dtype = 'int64')\n",
    "    data['goout']    = np.array(data.goout, dtype = 'int64')\n",
    "    data['Dalc']     = np.array(data.Dalc, dtype = 'int64')\n",
    "    data['Walc']     = np.array(data.Walc, dtype = 'int64')\n",
    "    data['health']   = np.array(data.health, dtype = 'int64')\n",
    "    \n",
    "    \n",
    "    data_transformed = encoder.transform(data)\n",
    "    \n",
    "    return nicks, mails, data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'credentials.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-978659709a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mSCOPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'https://www.googleapis.com/auth/spreadsheets.readonly'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m flow = InstalledAppFlow.from_client_secrets_file(\n\u001b[0;32m----> 3\u001b[0;31m                 'credentials.json', SCOPES)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.1/lib/python3.7/site-packages/google_auth_oauthlib/flow.py\u001b[0m in \u001b[0;36mfrom_client_secrets_file\u001b[0;34m(cls, client_secrets_file, scopes, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mFlow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mconstructed\u001b[0m \u001b[0mFlow\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \"\"\"\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_secrets_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mclient_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'credentials.json'"
     ]
    }
   ],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)\n",
    "creds = flow.run_local_server(port=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = build('sheets', 'v4',credentials=creds)\n",
    "sheet = service.spreadsheets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SPREADSHEET_ID = '1e1tWLI0vD05bUj-wLWicOnl0iU-GWz0aaWEtRDlTQ2M'\n",
    "\n",
    "cols = \"AG\"\n",
    "rows = 4000\n",
    "\n",
    "SAMPLE_RANGE_NAME = 'A1:'+ cols + str(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RANGE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sheet.values().get(spreadsheetId=SAMPLE_SPREADSHEET_ID,\n",
    "                                range=SAMPLE_RANGE_NAME).execute()\n",
    "values = result.get('values', [])\n",
    "data = pd.DataFrame(values)\n",
    "data.columns = data.iloc[0,:]\n",
    "data = data.iloc[1:,:]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m, df_parsed = parse(data, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "target = np.where(y=='yes', 1, 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_one_hot,\n",
    "                                                    target, test_size = 0.2, random_state = 666)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(max_depth = 7,\n",
    "                              booster = \"dart\",\n",
    "                              colsample_bytree = 0.3,\n",
    "                              learning_rate = 0.39,\n",
    "                              reg_alpha = 0.9,\n",
    "                              reg_lambda = 1.8,\n",
    "                              subsample = 0.8)\n",
    "xgb_model.fit(X_train,y_train)\n",
    "\n",
    "#y_prob = xgb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "xgb_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.predict_proba(df_parsed)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, y_predict_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
