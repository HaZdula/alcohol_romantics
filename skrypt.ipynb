{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from cred import key\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from time import sleep \n",
    "\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "from watcher import entries_processed\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(data, encoder):\n",
    "    \"\"\"\n",
    "    Parsing data to the same format as in \"students-all.csv\"\n",
    "    \n",
    "    returns: nicks array and dataframe\n",
    "    \"\"\"\n",
    "    nicks = np.array(data['Nick'])\n",
    "    mails = np.array(data['Feedback mail'])\n",
    "    data = data.iloc[:, 2:-1]\n",
    "\n",
    "    column_names = [\n",
    "        'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob',\n",
    "        'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures',\n",
    "        'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'internet',\n",
    "        'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences',\n",
    "        'G1', 'G2', 'G3'\n",
    "    ]\n",
    "\n",
    "    data.columns = column_names\n",
    "\n",
    "    # deafults\n",
    "    data['school'] = np.repeat(\"GP\", data.shape[0])\n",
    "    data['major'] = np.repeat(\"mat\", data.shape[0])\n",
    "    data['higher'] = np.repeat(\"yes\", data.shape[0])\n",
    "\n",
    "    # corect order\n",
    "    data = data[[\n",
    "        'school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu',\n",
    "        'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime',\n",
    "        'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities',\n",
    "        'nursery', 'higher', 'internet', 'famrel', 'freetime', 'goout', 'Dalc',\n",
    "        'Walc', 'health', 'absences', 'G1', 'G2', 'G3', 'major'\n",
    "    ]]\n",
    "    \n",
    "    data['age'] = pd.to_numeric(data['age'])\n",
    "    data['sex'] = np.where(data.sex == 'Male', 'M', 'F')\n",
    "    data['address'] = np.where(data.address == 'Rural', 'R', 'U')\n",
    "    data['famsize'] = np.where(data.famsize == 'more than 3', 'GT3', 'LE3')\n",
    "    data['Pstatus'] = np.where(data.Pstatus == 'living apart', 'A', 'T')\n",
    "\n",
    "    d1 = {\n",
    "        'none': 0,\n",
    "        'primary education': 1,\n",
    "        'middle school': 2,\n",
    "        'high school': 3,\n",
    "        'higher education': 4\n",
    "    }\n",
    "\n",
    "    data['Medu'] = [d1[item] for item in list(data.Medu)]\n",
    "    data['Fedu'] = [d1[item] for item in list(data.Fedu)]\n",
    "\n",
    "    d2 = {\n",
    "        'teacher': 'teacher',\n",
    "        'healthcare': 'health',\n",
    "        'civil services': 'civil',\n",
    "        'home': 'at_home',\n",
    "        'other': 'other'\n",
    "    }\n",
    "\n",
    "    data['Mjob'] = [d2[item] for item in list(data.Mjob)]\n",
    "    data['Fjob'] = [d2[item] for item in list(data.Fjob)]\n",
    "\n",
    "    d3 = {\n",
    "        'close to home': 'home',\n",
    "        'school reputation': 'reputation',\n",
    "        'course preference': 'course',\n",
    "        'other': 'other'\n",
    "    }\n",
    "\n",
    "    data['reason'] = [d3[item] for item in list(data.reason)]\n",
    "    \n",
    "    d4 = {'Mother':'mother', 'Father':'father', 'other':'other'}\n",
    "    \n",
    "    data['guardian'] = [d4[item] for item in list(data.guardian)]\n",
    "\n",
    "    d5 = {'< 15':1, '15-30':2, '30-60':3,'60 >':4}\n",
    "    \n",
    "    data['traveltime'] = [d5[item] for item in list(data.traveltime)]\n",
    "    \n",
    "    d6 = {'< 2':1, '2-5':2, '5-10':3,'10 >':4}\n",
    "    \n",
    "    data['studytime'] = [d6[item] for item in list(data.studytime)]\n",
    "    \n",
    "    data['G1'] = np.array(((pd.to_numeric(data.G1) -2 )/3)*20 , dtype = 'int64')\n",
    "    data['G2'] = np.array(((pd.to_numeric(data.G2) -2 )/3)*20 , dtype = 'int64') \n",
    "    data['G3'] = np.array(((pd.to_numeric(data.G3) -2 )/3)*20 , dtype = 'int64')\n",
    "    \n",
    "    data['absences'] = np.array(pd.to_numeric(data.absences) , dtype = 'int64')\n",
    "    data['failures'] = np.array(data.failures, dtype = 'int64')\n",
    "    data['famrel']   = np.array(data.famrel, dtype = 'int64')\n",
    "    data['freetime'] = np.array(data.freetime, dtype = 'int64')\n",
    "    data['goout']    = np.array(data.goout, dtype = 'int64')\n",
    "    data['Dalc']     = np.array(data.Dalc, dtype = 'int64')\n",
    "    data['Walc']     = np.array(data.Walc, dtype = 'int64')\n",
    "    data['health']   = np.array(data.health, dtype = 'int64')\n",
    "    \n",
    "    \n",
    "    data_transformed = encoder.transform(data)\n",
    "    \n",
    "    return nicks, mails, data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_entries(entries_processed,\n",
    "                    encoder,\n",
    "                    rows = 5000, \n",
    "                    SAMPLE_SPREADSHEET_ID = '1e1tWLI0vD05bUj-wLWicOnl0iU-GWz0aaWEtRDlTQ2M'):\n",
    "    \n",
    "    cols = \"AG\"\n",
    "    SAMPLE_RANGE_NAME = 'A1:'+ cols + str(rows)\n",
    "    result = sheet.values().get(spreadsheetId=SAMPLE_SPREADSHEET_ID,\n",
    "                                range=SAMPLE_RANGE_NAME).execute()\n",
    "    values = result.get('values', [])\n",
    "    data = pd.DataFrame(values)\n",
    "    data.columns = data.iloc[0,:]\n",
    "    data = data.iloc[1+entries_processed:,:]\n",
    "    print('Processing from rows: {}. Got {} new entries'.format(entries_processed, data.shape[0]))\n",
    "    \n",
    "    n,m,df = parse(data, encoder)\n",
    "    return n,m,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new_entries(df, model):\n",
    "    \n",
    "    y_predict = model.predict(df)\n",
    "    y_predict_prob = model.predict_proba(df)[:,1]\n",
    "    \n",
    "    return y_predict, y_predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_response(nick, send_to_email, result, prob):\n",
    "    email = \"AlcoholRomantics@gmail.com\"\n",
    "    password = \"Fajny!Alkohol0\"\n",
    "\n",
    "    subject = \"Student, do you have partner?\"\n",
    "    message = 'Hi, {}'.format(nick)\n",
    "    message += \"\\n\\nThank you for participating in our survey! Here are your results: \"\n",
    "\n",
    "    if result == 0:\n",
    "        message += '\\nForever alone'\n",
    "    else:\n",
    "        message += '\\nYou have partner!'\n",
    "    \n",
    "    message += '\\nYour probability of being in romantic relationship is: {}'.format(prob)\n",
    "    message += '\\n\\nThis result was predicted by machine learning model trained on Student Alcohol Consumption dataset from University Of Camerino'\n",
    "    \n",
    "    message += '\\n\\nSee you next time!'\n",
    "    \n",
    "    msg = MIMEMultipart()\n",
    "    msg[\"From\"] = email\n",
    "    msg[\"To\"] = send_to_email\n",
    "    msg[\"Subject\"] = subject\n",
    "\n",
    "    msg.attach(MIMEText(message, 'plain'))\n",
    "\n",
    "    try: \n",
    "        server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n",
    "        server.starttls()\n",
    "        server.login(email, password)\n",
    "        text = msg.as_string()\n",
    "        server.sendmail(email, send_to_email, text)\n",
    "        server.quit()\n",
    "        print('Sent mail to {}, {}'.format(nick, send_to_email))\n",
    "    \n",
    "    except:\n",
    "        print('Error in sending')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notify_users(n,m,y_predict, y_predict_prob, sleep_time = 0.5):\n",
    "    for i in range(len(n)):\n",
    "        if m[i]:\n",
    "            send_response(n[i], m[i], y_predict[i], y_predict_prob[i])\n",
    "            sleep(sleep_time)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(model, encoder, small_sleep_time):\n",
    "    \n",
    "    f = open(\"./watcher.py\", \"r\")\n",
    "    entries_processed = int(f.read()[18:])\n",
    "    f.close()\n",
    "    \n",
    "    n,m,df = get_new_entries(entries_processed, encoder)\n",
    "    \n",
    "    if len(n) == 0: return\n",
    "    \n",
    "    y_predict, y_predict_prob = predict_new_entries(df, model)\n",
    "    notify_users(n,m,y_predict, y_predict_prob)\n",
    "    \n",
    "    f = open(\"./watcher.py\", \"w\")\n",
    "    f.write(\"entries_processed={}\".format(entries_processed + len(n)))\n",
    "    f.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_update(model,\n",
    "               encoder, \n",
    "               big_sleep_time=60, \n",
    "               small_sleep_time=0.5):\n",
    "    \n",
    "    while True:\n",
    "        update(model, encoder, small_sleep_time)\n",
    "        sleep(big_sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = build('sheets', 'v4',developerKey=key)\n",
    "sheet = service.spreadsheets()\n",
    "#SAMPLE_SPREADSHEET_ID = '1e1tWLI0vD05bUj-wLWicOnl0iU-GWz0aaWEtRDlTQ2M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.39, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0.9,\n",
       "              reg_lambda=1.8, scale_pos_weight=1, subsample=0.8,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "df = pd.read_csv(\"students-all.csv\")\n",
    "# remove rownames\n",
    "df = df.iloc[:,1:]\n",
    "\n",
    "encoder = ce.OneHotEncoder()\n",
    "\n",
    "df = pd.read_csv(\"students-all.csv\").iloc[:,1:]\n",
    "y = df.romantic\n",
    "df = df.drop(\"romantic\", axis =1)\n",
    "\n",
    "df_one_hot = encoder.fit_transform(df)\n",
    "\n",
    "target = np.where(y=='yes', 1, 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_one_hot,\n",
    "                                                    target, test_size = 0.2, random_state = 666)\n",
    "\n",
    "'''\n",
    "xgb_model = xgb.XGBClassifier(max_depth = 7,\n",
    "                              booster = \"dart\",\n",
    "                              colsample_bytree = 0.3,\n",
    "                              learning_rate = 0.39,\n",
    "                              reg_alpha = 0.9,\n",
    "                              reg_lambda = 1.8,\n",
    "                              subsample = 0.8)\n",
    "xgb_model.fit(X_train,y_train)\n",
    "'''\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.load_model('alco.model')\n",
    "\n",
    "#y_prob = xgb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "#y_predict_prob = xgb_model.predict_proba(df)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8041666666666667"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_prob = xgb_model.predict_proba(X_test)[:,1]\n",
    "y_pres = xgb_model.predict(X_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, y_predict_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing from rows: 12. Got 0 new entries\n",
      "Processing from rows: 12. Got 0 new entries\n",
      "Processing from rows: 12. Got 0 new entries\n",
      "Processing from rows: 12. Got 0 new entries\n",
      "Processing from rows: 12. Got 0 new entries\n",
      "Processing from rows: 12. Got 1 new entries\n",
      "Sent mail to przysiąść fałdów, aleksandrap1869@gmail.com\n",
      "Processing from rows: 13. Got 0 new entries\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-b33d67c2ff21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minf_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_sleep_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-c45c89799f13>\u001b[0m in \u001b[0;36minf_update\u001b[0;34m(model, encoder, big_sleep_time, small_sleep_time)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_sleep_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_sleep_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inf_update(xgb_model,encoder, big_sleep_time=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('3.7.1': pyenv)",
   "language": "python",
   "name": "python37164bit371pyenv8b58cff780124c0e86c6832805abcd0c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
